--- 
layout: post 
title: "Dask e novidades" 
date: 2025-06-08 
categories: [] 
--- 
**Dask** √© uma biblioteca Python voltada para computa√ß√£o paralela e distribu√≠da, ideal para quem trabalha com grandes volumes de dados e precisa escalar al√©m do que o `pandas` e `NumPy` conseguem oferecer em mem√≥ria.
---
## ‚öôÔ∏è O que √© Dask?
Dask permite executar opera√ß√µes em paralelo usando m√∫ltiplos n√∫cleos ou at√© clusters distribu√≠dos. Ele replica APIs conhecidas como `pandas`, `NumPy` e `scikit-learn`, facilitando a migra√ß√£o de c√≥digo existente para ambientes mais escal√°veis.
Principais componentes:
- **Dask DataFrame**: similar ao `pandas`, mas com suporte a dados maiores que a RAM.
- **Dask Array**: similar ao `NumPy`, com paralelismo autom√°tico.
- **Dask Delayed**: permite construir pipelines de execu√ß√£o pregui√ßosa.
- **Dask ML**: integra com `scikit-learn` para treinar modelos em paralelo.
---
## üöÄ Novidades recentes
### 1. Integra√ß√£o com Arrow e Parquet
Dask agora tem suporte aprimorado para leitura e escrita de arquivos **Apache Arrow** e **Parquet**, otimizando o desempenho em pipelines de dados modernos.
### 2. Suporte a GPUs com RAPIDS
Com a integra√ß√£o ao ecossistema **RAPIDS**, √© poss√≠vel usar Dask com GPUs para acelerar opera√ß√µes de DataFrame e Machine Learning, especialmente √∫til em ambientes com CUDA.
### 3. Scheduler adaptativo
O novo scheduler adaptativo permite que Dask ajuste dinamicamente o n√∫mero de workers com base na carga de trabalho, melhorando o uso de recursos em clusters.
### 4. Melhorias no Dask Gateway
O **Dask Gateway** facilita a cria√ß√£o e gerenciamento de clusters em ambientes como Kubernetes, JupyterHub e HPC. A interface foi simplificada e agora suporta autentica√ß√£o integrada.
---
## üß™ Exemplos de uso
### Leitura de dados em paralelo:
```python
import dask.dataframe as dd
df = dd.read_csv('dados/*.csv')
resultado = df.groupby('categoria').valor.mean().compute()
